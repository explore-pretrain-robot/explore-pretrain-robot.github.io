<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods.">
  <meta name="keywords" content="Visual Pre-training, Robot Manipulation, Visual Semantics, Temporal Dynamics">
  <meta name="viewport" content="width=device-width, initial-scale=0.8, font-size: 12px">
  <title>Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Ya Jing<sup>*</sup>,
            </span>
            <span class="author-block">
              Xuelin Zhu<sup>*</sup>,
            </span>
            <span class="author-block">
              Xingbin Liu<sup>*</sup>,
            </span>
            <span class="author-block">
              Qie Sima,
            </span>
            <span class="author-block">
              Taozheng Yang,
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Yunhai Feng,
            </span>
              <span class="author-block">
              Tao Kong
            </span>
          </div>
          <br>

          <div class="is-size-5 publication-authors">
            <span class="author-block">ByteDance Research &nbsp;&nbsp;</span>
            <span class="author-block"><sup>*</sup>Equal Contribution </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="publication-video">
          <iframe src="https://www.youtube.com"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!-- /Paper video. -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Visual pre-training with large-scale real-world data has made great progress in recent years, showing great potential in robot learning with pixel observations. However, the recipes of visual pre-training for robot manipulation tasks are yet to be built. In this paper, we thoroughly investigate the effects of visual pre-training strategies on robot manipulation tasks from three fundamental perspectives: pre-training datasets, model architectures and training methods. Several significant experimental findings are provided that are beneficial for robot learning. Further, we propose a visual pre-training scheme for robot manipulation termed Vi-PRoM, which combines self-supervised learning and supervised learning. Concretely, the former employs contrastive learning to acquire underlying patterns from large-scale unlabeled data, while the latter aims learning visual semantics and temporal dynamics. Extensive experiments on robot manipulations in various simulation environments and the real robot demonstrate the superiority of the proposed scheme.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method -->
     <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Roadmap</h2>
        <div class="content has-text-justified">
          <!-- <img id="model" align="right" width="50%" src="static/images/roadmap.jpg"> -->
          <!-- <div style="width: 45%;"> -->
          <p>
            We first conduct extensive studies on visual pre-training from three fundamental aspects: datasets, models and methods that may influence the performance of robot learning. To facilitate the fundamental studies, we also propose a new dataset named EgoNet, which is created based on Ego4d and contains a large-scale egocentric video clips rich in human-object interactions. EgoNet has the potential to serve as a benchmark to pre-train visual models for robot manipulations. </p>
        <!-- </div> -->
        
        <!-- <h3 class="has-text-centered">
          <p style="font-family:Times New Roman"><b>We need a figure or GIF/MP4 here to show the method.</b></p>
        </h3> -->

      </div>
      <img id="model" width="50%" src="static/images/roadmap.jpg">
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Method -->
     <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Approach</h2>
        <div class="content has-text-justified">
          <p>
            Based on empirical findings, we propose a visual pre-training scheme termed Vi-PRoM for robot manipulations, which sequentially trains a visual encoder using self-supervised learning and supervised fine-tuning. Concretely, the visual encoder is first pre-trained based on contrastive learning, allowing the trained model to acquire sequential patterns implicitly for the input data. Then, supervised learning is applied by constructing pseudo-labels and temporal labels to encourage the visual encoder further to perceive visual semantics and temporal dynamics.  </p>
        </div>
        <img id="model" width="100%" src="static/images/viprom.jpg ">
        <!-- <h3 class="has-text-centered">
          <p style="font-family:Times New Roman"><b>We need a figure or GIF/MP4 here to show the method.</b></p>
        </h3> -->

      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results 1 -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Results</h2>
      <div class="columns is-centered">
      <!--Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/fk_opening_door.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Visual-Force Imitation. -->

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/fk_opening_microwave.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/fk_sliding_door.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/fk_turning_knob.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/fk_turning_on_light.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>



    </div>

    <div class="columns is-centered has-text-centered">
      <!--Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <!-- <img id="model" width="100%" src="static/videos/mw_assembling_ring.gif"> -->
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/mw_assembling_ring.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Visual-Force Imitation. -->

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/mw_hammering_nail.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/mw_opening_drawer.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/mw_picking_placing.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/mw_pushing_button.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

    </div>


    <div class="columns is-centered has-text-centered">
      <!--Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <!-- <img id="model" width="100%" src="static/videos/mw_assembling_ring.gif"> -->
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/rr_opening_drawer.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Visual-Force Imitation. -->

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/rr_closing_drawer.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>


    <div class="columns is-centered has-text-centered">
      <!--Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <!-- <img id="model" width="100%" src="static/videos/mw_assembling_ring.gif"> -->
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/rr_opening_door.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Visual-Force Imitation. -->

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p></p>
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/rr_closing_door.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>

  </div>

  </div>

</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    @inproceedings{jing2023explore
      author    = {Ya Jing, Xuelin Zhu, Xingbin Liu, Qie Sima, Taozheng Yang, Yunhai Feng, Tao Kong},
      title     = {Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods},
      booktitle = {2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
      year      = {2023}
    }
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
        <div class="content">
          <p>
            The website template was adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
  </div>
</footer>

</body>
</html>
