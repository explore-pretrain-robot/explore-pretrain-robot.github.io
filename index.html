<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods.">
  <meta name="keywords" content="Visual Pre-training, Robot Manipulation, Visual Semantics, Temporal Dynamics">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Ya Jing<sup>*</sup>,
            </span>
            <span class="author-block">
              Xuelin Zhu<sup>*</sup>,
            </span>
            <span class="author-block">
              Xingbin Liu<sup>*</sup>,
            </span>
            <span class="author-block">
              Qie Sima,
            </span>
            <span class="author-block">
              Taozheng Yang,
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Yunhai Feng,
            </span>
              <span class="author-block">
              Tao Kong,
            </span>
          </div>
          <br>

          <div class="is-size-5 publication-authors">
            <span class="author-block">ByteDance Research &nbsp;&nbsp;</span>
            <span class="author-block"><sup>*</sup>Equal Contribution </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="publication-video">
          <iframe src="https://www.youtube.com"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!-- /Paper video. -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Visual pre-training with large-scale real-world data has made great progress in recent years, showing great potential 
            in robot learning with pixel observations. However, the recipes of visual pre-training for robot manipulation tasks are 
            yet to be built. In this paper, we thoroughly investigate the effects of visual pre-training strategies on robot manipulation 
            tasks from three fundamental perspectives: pre-training datasets, model architectures and training methods. Several 
            significant experimental findings are provided regarding pre-training paradigms that are beneficial for robot learning. 
            Further, we propose a visual pre-training scheme for robot manipulation termed Vi-PRoM, which combines self-supervised 
            learning and supervised learning. Concretely, the former employs contrastive learning to acquire underlying patterns from 
            large-scale unlabeled data, while the latter allows learning visual semantics and temporal dynamics. In this way, 
            the well-trained visual encoder is able to produce a comprehensive representation for the pixel input, thus facilitating 
            robot manipulation tasks. Extensive experiments on robot manipulations in various simulation environments and the real 
            robot demonstrate the superiority of the proposed scheme. </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method -->
     <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Visual-Force Imitation</h2>
        <div class="content has-text-justified">
          <p>
            We first collect expert trajectories for multiple tasks. The observation images of the expert data are
            converted to representation vectors by a visual encoder. In the rollout, the observation image is converted
            to a representation vector with the same visual encoder. The action and target wrench are predicted by
            retrieving the actions from the expert data by comparing the similarity of the representation vectors.
            We use admittance whole-body control to control the robot.</p>
        </div>
        <img id="model" width="100%" src="static/images/framework.jpeg">
        <h3 class="has-text-centered">
          <p style="font-family:Times New Roman"><b>We need a figure or GIF/MP4 here to show the method.</b></p>
        </h3>

      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Results 1 -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Results</h2>
      <div class="columns is-centered">
      <!--Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p>With Visual-Force Imitation</p>
            <video id="Open-left-door" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Visual-Force Imitation. -->

      <!-- Without Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p>Without Visual-Force Imitation</p>
            <video id="Open-cabinet-drawer" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Without Visual-Force Imitation. -->

       <!-- Joint torque results. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p>Joint torque results</p>
            <video id="Joint-torque-results" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Joint torque results . -->

    </div>
    </div>
    </div>
    <!--/ Results 1 -->

    <!-- Results 2 -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
      <div class="columns is-centered">
      <!--Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="Open-left-doore" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Visual-Force Imitation. -->

      <!-- Without Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="Open-cabinet-drawer1" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Without Visual-Force Imitation. -->

       <!-- Joint torque results. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="Joint-torque-results2" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Joint torque results . -->

    </div>
    </div>
    </div>
    <!--/ Results 2 -->

    <!-- Results 3 -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
      <div class="columns is-centered">
      <!--Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="Open-left-door3" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Visual-Force Imitation. -->

      <!-- Without Visual-Force Imitation. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="Open-cabinet-drawer4" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Without Visual-Force Imitation. -->

       <!-- Joint torque results. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <video id="Joint-torque-results5" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!--/ Joint torque results . -->

    </div>
    </div>
    </div>
    <!--/ Results 3 -->



  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    @inproceedings{jing2023explore
      author    = {Ya Jing, Xuelin Zhu, Xingbin Liu, Qie Sima, Taozheng Yang, Yunhai Feng, Tao Kong},
      title     = {Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods},
      booktitle = {2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
      year      = {2023}
    }
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
        <div class="content">
          <p>
            The website template was adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
  </div>
</footer>

</body>
</html>
